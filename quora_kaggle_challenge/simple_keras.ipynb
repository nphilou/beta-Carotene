{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import os\nimport time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Train shape :  (1306122, 3)\nTest shape :  (375806, 2)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "train_df \u003d pd.read_csv(\"train.csv\")\ntest_df \u003d pd.read_csv(\"test.csv\")\nprint(\"Train shape : \",train_df.shape)\nprint(\"Test shape : \",test_df.shape)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Index([\u0027qid\u0027, \u0027question_text\u0027, \u0027target\u0027], dtype\u003d\u0027object\u0027)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(train_df.columns)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[\u0027how did quebec nationalists see their province as a nation in the 1960s?\u0027\n \u0027do you have an adopted dog, how would you encourage people to adopt and not shop?\u0027\n \u0027why does velocity affect time? does velocity affect space geometry?\u0027 ...\n \u0027is foam insulation toxic?\u0027\n \u0027how can one start a research project based on biochemistry at ug level?\u0027\n \u0027who wins in a battle between a wolverine and a puma?\u0027]\n",
            "[[    0     0     0 ...     6     1  8333]\n [    0     0     0 ...    10    44  1846]\n [    0     0     0 ...   374   451  5546]\n ...\n [    0     0     0 ...  7760 11663  2984]\n [    0     0     0 ...    43  3384   422]\n [    0     0     0 ...    10     4 21972]]\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_data_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_data_rate_limit\u003d1000000.0 (bytes/sec)\nNotebookApp.rate_limit_window\u003d3.0 (secs)\n\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "maxlen \u003d 72\n\nvectorizer \u003d TfidfVectorizer(\n    strip_accents\u003d\u0027unicode\u0027,\n    ngram_range\u003d(1, 3),\n    analyzer\u003d\u0027word\u0027,\n    min_df\u003d3, max_df\u003d0.9, max_features\u003dNone,\n    use_idf\u003dTrue, smooth_idf\u003dTrue, sublinear_tf\u003dTrue,\n    stop_words\u003d\u0027english\u0027)\n\ntrain_df[\"question_text\"] \u003d train_df[\"question_text\"].str.lower()\ntest_df[\"question_text\"] \u003d test_df[\"question_text\"].str.lower()\n\nX \u003d train_df[\"question_text\"].fillna(\"_NA\").values\nX_test \u003d test_df[\"question_text\"].fillna(\"_NA\").values\n\nprint(X)\n\ntokenizer \u003d Tokenizer()\ntokenizer.fit_on_texts(list(X))\n\nX \u003d tokenizer.texts_to_sequences(X)\nX_test \u003d tokenizer.texts_to_sequences(X_test)\n\nprint(X)\n\nX \u003d pad_sequences(X, maxlen\u003dmaxlen)\nX_test \u003d pad_sequences(X_test, maxlen\u003dmaxlen)\n\nprint(X)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "pycharm-11c4cb55",
      "language": "python",
      "display_name": "PyCharm (beta-Carotene)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}